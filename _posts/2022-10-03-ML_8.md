---
layout: single
title: "[ML-1] 08. Model Selection"
categories: ML
tag: [ML]
toc: true
author_profile: false
sidebar:
nav: "docs"
---

- 본 포스팅은 Introduction to Statistical Learning(ISL) 교재를 기반으로 작성되었습니다.





# Linear Model Selection and Regularization

  

- linear model: [그림]![img](http://www.sciweavers.org/upload/Tex2Img_1664814100/render.png)
- linear model은 해석 상의 이점이 있고, 예측의 성능이 좋은 경우도 존재한다.
- 따라서, linear model을 개선하고, 일반적인 LSE를 대체할 수 있는 다른 방법을 찾아본다.





### Why consider 

계수가 존재하고, p+1개 항이 있고 -> LSE로 계수를 구하면 되지 않나~

1. 예측 정확도: 만약에 데이터량(n)보다 변수(p)가 많다면, 즉 고차원 데이터라면 분산을 조절하는 대책이 필요하다.
2. 모델 해석: p개의 변수들 중에서, 상관없는 feature를 없애는 방법이 필요하다. performance가 비슷하다면, complexity가 낮은 모델을 선호하는 것과 같은 맥락이다.



# Three classes of Methods

1. Subset Selection
2. Shrinkage
3. Dimension Reduction