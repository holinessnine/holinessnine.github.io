---
layout: single
title: "[ML-1] 07. Bootstrap"
categories: ML
tag: [ML, bootstrap]
toc: true
author_profile: false
sidebar:
nav: "docs"
---



- 본 포스팅은 Introduction to Statistical Learning(ISL) 교재를 기반으로 작성되었습니다.



# What is Bootstrap?

  

하나의 데이터셋에서: **<u>여러 개의 데이터셋 샘플</u>**을 만들어 내는 방법(복제본 처럼)



coefficient의 standard error, y의 신뢰구간을 얻고 싶을 때: 하나의 데이터셋만으로는 힘들 때가 있다

neural network에서도 동일한 문제가 발생한다.



-> bootstrap을 사용해서 outcome의 standard error/uncertainty를 구할 수 있다!



통계에서의 bootstrap:  데이터를 어떻게 끄집어내서 더 additional information을 구할 수 있을까 하는 문제



### sample example

x, y라는 asset이 있을 때, x에 alpha만큼, y에 1-alpha만큼 투자를 한다.

risk(variance)를 최소화하고 싶다! -> 즉 (Var(aX + (1-a)Y))를 최소화 하고 싶은 것!

x와 y 각각의 variance 그리고 covariance를 안다고 하면, 그 두개를 가지고 optimal한 alpha값을 구할 수 있다!



실제로는: true distribution을 모른다.



[그림]

100개의 simulation마다 alpha값을 구할 수 있다.



[그림]

alpha값을 한 번만 구하는 것이 아니라, 

alpha값은 random하다. 이 때 alpha의 standard deviation(uncertinaty)은?

- x,y 페어를 여러번 simulate했다. (100쌍을 1000번) -> 1000개의 alpha값이 계산된다.
- true alpha=0.6이었고, 1000번의 simulated alpha를 평균냈더니 0.6에 근사했다!
- simulated alpha의 standard deviation 역시 0.083으로 작았다. (평균에서 0.083정도 떨어져 있다)
- 왼쪽: 실제 데이터를 1000번(총 데이터 10만개) / 중간: 샘플 데이터셋 1000개(총 데이터 100개)



즉 Bootstrap은 마치 데이터를 더 많이 끌어오는 것과 같은 효과를 얻기 위해 사용한다.

- 가장 중요: 원래의 데이터셋을 sample하는 것(복원 추출로!): sample dataset의 크기가 original dataset의 크기와 같게끔
- 한 sample dataset에서 어떤 data는 여러 번 들어갈 수도, 어떤 data는 안들어갈 수도 있다.

  

[그림]

original data와 sample data는 서로 다른 dataset이다. 하지만 distribution은 같다.

각 sample dataset을 가지고 alpha를 구한다. 각각의 alpha는 다르다.



- 중요: 더 많은 데이터를 학습해서 성능이 좋아진다의 의미가 아닌, estimation의 uncertainty를 알고자 하는 것!



### Bootstrap in general





### Can the bootstrap estimate prediction error?

- Cross-validation: train - validation set 사이에 overlap이 없었다.
- bootstrap을 통해 prediction error를 추정하려면: overlap 때문에 문제가 발생한다! 원래 dataset의 약 2/3가 sample dataset에 포함된다. (overlap의 정도가 심각함) 그 이유는? [그림]
- 다시 말해, true prediction error를 심각하게 underestimate한다.



### Removing the overlap

- bootstrap sample data에 나타나지 않은 datapoint를 가지고 예측을 하는 방법이 가능하다.
- 하지만 이런 방법은 복잡하고, 따지고 보면 cross-validation이 prediction error를 더 쉽고 잘 추정하기 때문에 크게 유의미하지는 않다.

